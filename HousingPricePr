import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
from xgboost import XGBRegressor
import plotly.express as px

class HousingPricePredictor:
    def __init__(self):
        self.rf_model = RandomForestRegressor(random_state=42)
        self.xgb_model = XGBRegressor(random_state=42)
        self.scaler = StandardScaler()
        
    def load_and_preprocess(self, data_path):
        """Load and preprocess housing data"""
        # Load data
        df = pd.read_csv(data_path)
        
        # Handle missing values
        df = df.fillna(df.mean())
        
        # Feature engineering
        df['age'] = 2024 - df['year_built']
        df['price_per_sqft'] = df['price'] / df['sqft_living']
        df['total_rooms'] = df['bedrooms'] + df['bathrooms']
        
        return df
    
    def create_features(self, df):
        """Create feature matrix X and target variable y"""
        # Select features
        features = ['sqft_living', 'bedrooms', 'bathrooms', 'age',
                   'floors', 'price_per_sqft', 'total_rooms']
        
        X = df[features]
        y = df['price']
        
        # Scale features
        X_scaled = self.scaler.fit_transform(X)
        
        return X_scaled, y
    
    def train_models(self, X, y):
        """Train Random Forest and XGBoost models"""
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Train Random Forest
        self.rf_model.fit(X_train, y_train)
        rf_pred = self.rf_model.predict(X_test)
        rf_score = r2_score(y_test, rf_pred)
        
        # Train XGBoost
        self.xgb_model.fit(X_train, y_train)
        xgb_pred = self.xgb_model.predict(X_test)
        xgb_score = r2_score(y_test, xgb_pred)
        
        return {
            'rf_score': rf_score,
            'xgb_score': xgb_score,
            'test_data': (X_test, y_test),
            'predictions': (rf_pred, xgb_pred)
        }
    
    def generate_visualizations(self, df, results):
        """Create visualizations for analysis"""
        # Price distribution
        plt.figure(figsize=(10, 6))
        sns.histplot(data=df, x='price', bins=50)
        plt.title('Distribution of House Prices')
        plt.savefig('price_distribution.png')
        
        # Feature importance
        feature_importance = pd.DataFrame({
            'feature': ['sqft_living', 'bedrooms', 'bathrooms', 'age',
                       'floors', 'price_per_sqft', 'total_rooms'],
            'importance': self.rf_model.feature_importances_
        })
        feature_importance = feature_importance.sort_values('importance', ascending=False)
        
        plt.figure(figsize=(10, 6))
        sns.barplot(data=feature_importance, x='importance', y='feature')
        plt.title('Feature Importance (Random Forest)')
        plt.savefig('feature_importance.png')
        
        # Actual vs Predicted prices
        X_test, y_test = results['test_data']
        rf_pred, xgb_pred = results['predictions']
        
        plt.figure(figsize=(10, 6))
        plt.scatter(y_test, rf_pred, alpha=0.5)
        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
        plt.xlabel('Actual Price')
        plt.ylabel('Predicted Price')
        plt.title('Actual vs Predicted House Prices')
        plt.savefig('prediction_scatter.png')

if __name__ == "__main__":
    # Initialize predictor
    predictor = HousingPricePredictor()
    
    # Load and process data
    df = predictor.load_and_preprocess('housing_data.csv')
    
    # Create features
    X, y = predictor.create_features(df)
    
    # Train models
    results = predictor.train_models(X, y)
    
    # Generate visualizations
    predictor.generate_visualizations(df, results)
    
    # Print model performance
    print(f"Random Forest R² Score: {results['rf_score']:.4f}")
    print(f"XGBoost R² Score: {results['xgb_score']:.4f}")
